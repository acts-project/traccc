/** TRACCC library, part of the ACTS project (R&D line)
 *
 * (c) 2025 CERN for the benefit of the ACTS project
 *
 * Mozilla Public License Version 2.0
 */

#pragma once

//cuda includes
#include <cuda.h>
#include <cuda_runtime.h>
#include <math_constants.h>
#include <vector_functions.h>
#include <cuda_fp16.h>

#include "traccc/cuda/gbts_seeding/gbts_seeding_algorithm.hpp"

namespace traccc::cuda::kernels {

struct __align__(8) half4 {
	__half x,y,z,w;
};

inline __device__ __host__ half4 make_half4(const __half x, const __half y, const __half z, const __half w) {
	half4 t;
	t.x = x;
	t.y = y;
	t.z = z;
	t.w = w;
	return t;
}

__global__ static void graphEdgeMakingKernel(const uint4* d_bin_pair_views, const float* d_bin_pair_dphi, const float* d_node_params, const gbts_algo_params* d_algo_params,
												 unsigned int* d_counters, int2* d_edge_nodes, half4* d_edge_params, unsigned int* d_num_outgoing_edges, 
												 unsigned int nMaxEdges, int nPhiBins) {
	__shared__ unsigned int begin_bin1;
	__shared__ unsigned int begin_bin2;
	__shared__ unsigned int num_nodes1;
	__shared__ unsigned int num_nodes2;
	__shared__ float deltaPhi;

	__shared__ float minDeltaRad;
	__shared__ float min_z0;
	__shared__ float max_z0;
	__shared__ float maxOuterRad;
	__shared__ float min_zU;
	__shared__ float max_zU;
	__shared__ float max_kappa;
	__shared__ float low_Kappa_d0;
	__shared__ float high_Kappa_d0;

	__shared__ float tau_min[traccc::device::gbts_consts::node_buffer_length];
	__shared__ float tau_max[traccc::device::gbts_consts::node_buffer_length];
	__shared__ float phi[traccc::device::gbts_consts::node_buffer_length];
	__shared__ float r[traccc::device::gbts_consts::node_buffer_length];
	__shared__ float z[traccc::device::gbts_consts::node_buffer_length];

	if(threadIdx.x == 0) {
		uint4 views    = d_bin_pair_views[blockIdx.x];
		deltaPhi       = d_bin_pair_dphi[blockIdx.x];
		 
		begin_bin1     = views.x;
		begin_bin2     = views.z;
		num_nodes1 = views.y - begin_bin1;
		num_nodes2 = views.w - begin_bin2;
		
		minDeltaRad    = d_algo_params->minDeltaRadius;
		min_z0         = d_algo_params->min_z0;
		max_z0         = d_algo_params->max_z0;
		maxOuterRad    = d_algo_params->maxOuterRadius;
		min_zU         = d_algo_params->cut_zMinU;
		max_zU         = d_algo_params->cut_zMaxU;
		max_kappa      = d_algo_params->max_Kappa;
		low_Kappa_d0   = d_algo_params->low_Kappa_d0;
		high_Kappa_d0  = d_algo_params->high_Kappa_d0;
	}

	__syncthreads();
	for(int idx = threadIdx.x; idx < num_nodes1; idx += blockDim.x) {//loading a chunk of nodes1 into shared mem buffers
		int offset = 5*(idx + begin_bin1);
		tau_min[idx] = d_node_params[offset];
		tau_max[idx] = d_node_params[offset+1];
		phi[idx]     = d_node_params[offset+2];
		r[idx]       = d_node_params[offset+3];
		z[idx]       = d_node_params[offset+4];
	}

	__syncthreads();

	int last_n1 = 0;//initial value for the sliding window

	float phi_bin_width = 2.0f * CUDART_PI_F / nPhiBins;

	for(int n2Idx = threadIdx.x; n2Idx < num_nodes2; n2Idx += blockDim.x) {
			
		int n1Idx = last_n1;

		int globalIdx2 = begin_bin2 + n2Idx;
		int o2 = 5*globalIdx2;
		
		float phi2 = d_node_params[2 + o2];
		
		float min_phi1 = phi2 - deltaPhi;
		float max_phi1 = phi2 + deltaPhi;
		
		if (min_phi1 < -CUDART_PI_F) min_phi1 += 2.0f * CUDART_PI_F;
		if (max_phi1 >  CUDART_PI_F) max_phi1 -= 2.0f * CUDART_PI_F;
						
		bool boundary = max_phi1 < min_phi1;// +/- pi wraparound

		//expand over nearest bin boundary
		max_phi1 += phi_bin_width;
		min_phi1 -= phi_bin_width;
		
		if(!boundary) {
			if(phi[0] > max_phi1) continue;
			if(phi[num_nodes1-1] < min_phi1) {
				if(phi[0] > deltaPhi+phi_bin_width-CUDART_PI_F) break; //if bin1 can't be part of a wraparound from a high-phi node skip it
				continue;
			}
		}
		else {
			if(phi[0] < max_phi1) n1Idx = 0; //if not to large for lower wraparound don't skip it
			else if(phi[num_nodes1 - 1] < min_phi1 ) continue;
		}        
		
		float tau_min2 = d_node_params[    o2];
		float tau_max2 = d_node_params[1 + o2];
		float r2       = d_node_params[3 + o2];
		float z2       = d_node_params[4 + o2];
		
		for(; n1Idx < num_nodes1; n1Idx++) {
			float phi1 = phi[n1Idx];

			if(!boundary) {
				if(phi1 > max_phi1) break;
				if(phi1 < min_phi1) continue;
				last_n1 = n1Idx;
			}
			else {
				if(phi1 > max_phi1 && phi1 < min_phi1) {
					if(n1Idx < last_n1) n1Idx = last_n1 - 1; // skip to high wraparound after the lower part is done
					continue;
				}
			}

			float r1 = r[n1Idx];
			float dr = r2-r1;
			 
			if(dr < minDeltaRad) continue;
			
			float z1 = z[n1Idx];
			float dz = z2 - z1;
			float tau = dz/dr;
			float ftau = fabsf(tau);
			
			if(ftau > 36.0f) continue; //detector acceptance
			
			if((ftau < tau_min2) || (ftau > tau_max2)) continue;

			if((ftau < tau_min[n1Idx]) || (ftau > tau_max[n1Idx])) continue;

			//RZ doublet filter cuts
			float z0 = z1 - r1*tau;
			if((z0 < min_z0) || (z0 > max_z0)) continue;
			
			float zouter = z0 + maxOuterRad*tau;

			if(zouter < min_zU || zouter > max_zU) continue;

			float dphi = phi2 - phi1;
			if(boundary) { 
				if (dphi < -CUDART_PI_F) dphi += 2.0f * CUDART_PI_F;
				else if (dphi > CUDART_PI_F) dphi -= 2.0f * CUDART_PI_F;
			}
		
			//needed for sliding phi window consistancy
			if(fabsf(dphi) > deltaPhi) continue;

			float curv = dphi/dr;
			float d0_for_max_curv = r1*r2*(fabsf(curv) - max_kappa);
			float d0_max = (ftau < 4.0f) ? low_Kappa_d0 : high_Kappa_d0;
			if(d0_for_max_curv > d0_max) continue;
			
			int nEdges = atomicAdd(&d_counters[0], 1);
			if(nEdges < nMaxEdges) {
				__half exp_eta = __float2half(sqrtf(1 + tau*tau) - tau);
				atomicAdd(&d_num_outgoing_edges[globalIdx2], 1);
				d_edge_nodes[nEdges]  = make_int2(begin_bin1 + n1Idx, globalIdx2);
				d_edge_params[nEdges] = make_half4(exp_eta, __float2half(curv), __float2half(phi1 + curv*r1), __float2half(phi2 + curv*r2));
			}
		}
	}
}

__global__ static void graphEdgeLinkingKernel(const int2* d_edge_nodes, int* d_edge_links, unsigned int* d_num_outgoing_edges, int nEdges) {

	int edge_idx = blockIdx.x * blockDim.x + threadIdx.x;

	if(edge_idx >= nEdges) return;
	int n2Idx = d_edge_nodes[edge_idx].y;//global index of n2

	unsigned int pos = atomicSub(&d_num_outgoing_edges[n2Idx], 1); //this converts num_outgoing_edges to the start postion for each node in d_edge_links
	d_edge_links[pos-1] = edge_idx; //this edge starts from n2, matching will check edge's n1 and then loop over edges outgoing from that node
}

__global__ static void graphEdgeMatchingKernel(const gbts_algo_params* d_algo_params, const half4* d_edge_params, const int2* d_edge_nodes, 
												   const unsigned int* d_num_outgoing_edges, const int* d_edge_links, 
												   unsigned char* d_num_neighbours, int* d_neighbours, int* d_reIndexer, unsigned int* d_counters, int nEdges, int nMaxNei) {
	__shared__ __half cut_dphi_max;
	__shared__ __half cut_dcurv_max;
	__shared__ __half cut_tau_ratio_max;
	__shared__ __half PI_h;
	__shared__ __half PI_2_h;
	__shared__ __half ONE_h;
	if(threadIdx.x == 0) {
		cut_dphi_max      = __float2half(d_algo_params->cut_dphi_max);
		cut_dcurv_max     = __float2half(d_algo_params->cut_dcurv_max);
		cut_tau_ratio_max = __float2half(d_algo_params->cut_tau_ratio_max);
		
		PI_h   = __float2half(CUDART_PI_F);
		PI_2_h = __float2half(2*CUDART_PI_F);
		ONE_h  = __float2half(1.0f);
	}
	__syncthreads();

	int edge1_idx = blockIdx.x * blockDim.x + threadIdx.x;

	if (edge1_idx >= nEdges) return;

	int n1Idx = d_edge_nodes[edge1_idx].x;//global index of n1 node of the edge1

	int link_begin = d_num_outgoing_edges[n1Idx];
	int nLinks = d_num_outgoing_edges[n1Idx+1] - link_begin;//the number of edges which has n1 as their starting node (n2)
	if (nLinks == 0) return;

	half4 params1 = d_edge_params[edge1_idx]; // [exp_eta, curv, Phi1, Phi2]

	__half uat_2  = ONE_h/params1.x;
	__half Phi2   = params1.z;
	__half curv2  = params1.y;

	int nei_pos  = nMaxNei*edge1_idx;

	unsigned char num_nei  = 0;

	for(int k=0;k<nLinks;k++) {//loop over potential neighbours

		if(num_nei >= nMaxNei) break;

		int edge2_idx = d_edge_links[link_begin + k];
		
		half4 params2 = d_edge_params[edge2_idx];
	
		__half tau_ratio = params2.x*uat_2 - ONE_h;

		if(__habs(tau_ratio) > cut_tau_ratio_max) {//bad match
			continue;
		}
		
		__half dPhi =  Phi2 - params2.w;//Phi2
	
		if (dPhi < -PI_h) dPhi += PI_2_h;
		else if (dPhi > PI_h) dPhi -= PI_2_h;
		if(__habs(dPhi) > cut_dphi_max) {
			continue;
		}
				
		__half dcurv = curv2 - params2.y;
				
		if(__habs(dcurv) > cut_dcurv_max) {
			continue;
		}
		
		d_neighbours[nei_pos + num_nei] = edge2_idx;
		d_reIndexer[edge2_idx] = 1;
				
		++num_nei;
	}

	d_num_neighbours[edge1_idx] = num_nei;

	if(num_nei!=0) {
		d_reIndexer[edge1_idx] = 1;
		atomicAdd(&d_counters[1], num_nei);
	}
}

__global__ void edgeReIndexingKernel(int* d_reIndexer, unsigned int* d_counters, int nEdges) {

	//each thread gets an edge      

	int edge_idx = threadIdx.x + blockIdx.x*blockDim.x;

	if(edge_idx >= nEdges) return;

	if(d_reIndexer[edge_idx] == -1) return;

	d_reIndexer[edge_idx] = atomicAdd(&d_counters[2], 1);
}

__global__ static void graphCompressionKernel(const int* d_orig_node_index, 
												  const int2* d_edge_nodes, const unsigned char* d_num_neighbours, const int* d_neighbours, 
												  const int* d_reIndexer, int* d_output_graph, int nEdgesPerBlock, int nEdges, int nMaxNei) {
	 
	int begin_edge = blockIdx.x * nEdgesPerBlock;
	int edge_size  = 2 + 1 + nMaxNei;

	for(int idx = threadIdx.x + begin_edge;idx < begin_edge + nEdgesPerBlock; idx += blockDim.x) {

		if(idx >= nEdges) continue;

		int newIdx = d_reIndexer[idx];
		if (newIdx == -1) continue;
		int pos = edge_size*newIdx;
		int2 edge_nodes = d_edge_nodes[idx];
		int node1_idx = d_orig_node_index[edge_nodes.x];
		d_output_graph[pos + traccc::device::gbts_consts::node1] = node1_idx;
		int node2_idx = d_orig_node_index[edge_nodes.y];
		d_output_graph[pos + traccc::device::gbts_consts::node2] = node2_idx;

		unsigned char nNei = d_num_neighbours[idx];
		d_output_graph[pos + traccc::device::gbts_consts::nNei] = nNei;
		int nei_pos = nMaxNei*idx;
		for(int k=0;k<nNei;k++) {
			d_output_graph[pos + traccc::device::gbts_consts::nei_start + k] = d_reIndexer[d_neighbours[nei_pos + k]];
		}
	}
}

} //traccc::cuda::kernels namespace
